{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Réseau à convolutions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import glob\n",
    "#from skimage import data, color\n",
    "#from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import random\n",
    "from PIL import Image, ImageFilter\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Dense(\n",
    "    units=64,\n",
    "    kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "    bias_initializer=initializers.Zeros()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2>Récupération des images</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "targets = []\n",
    "\n",
    "# on redimensionne les images\n",
    "\n",
    "files = glob.glob(\"1/*.jpg\")\n",
    "random.shuffle(files)\n",
    "\n",
    "for file in files:\n",
    "    features.append(np.array(Image.open(file).resize((75,75))))\n",
    "    #target = [1,0] if \"cat\" in file else [0,1]\n",
    "    target = [1] if \"cat\" in file else [0]\n",
    "    targets.append(target)\n",
    "\n",
    "   \n",
    "features = np.array(features)\n",
    "targets = np.array(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2>Découpage du dataset pour validation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(features,targets, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = tf.image.convert_image_dtype(X_train, dtype=tf.float32, saturate=False)\n",
    "X_valid = tf.image.convert_image_dtype(X_valid, dtype=tf.float32, saturate=False)\n",
    "y_train = tf.image.convert_image_dtype(y_train, dtype=tf.float32, saturate=False)\n",
    "y_valid = tf.image.convert_image_dtype(y_valid, dtype=tf.float32, saturate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2>Normalisation des données</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(X_train)\n",
    "normalized_data = layer(X_train)\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(X_valid)\n",
    "normalized_data = layer(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Préparation du pipeline des données avec Tensorflow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Découpage de l'epoch en batch</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 75, 75, 3) (32, 1)\n"
     ]
    }
   ],
   "source": [
    "#création d'un batch de 32 elements : tuple d'images et de sa target\n",
    "epoch = 1\n",
    "batch_size = 32\n",
    "for images_batch,targets_batch in train_dataset.repeat(epoch).batch(32):\n",
    "    print(images_batch.shape, targets_batch.shape)\n",
    "    break\n",
    "\n",
    "images_batch = tf.image.convert_image_dtype(images_batch, dtype=tf.float32, saturate=False)    \n",
    "targets_batch = tf.image.convert_image_dtype(targets_batch, dtype=tf.float32, saturate=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Définition du modèle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        #Convolutions (création du constructeur) :\n",
    "        # conv1 transforme en 32 images (filtre) de 25 x 25 pixels :\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 4, activation='relu', name=\"conv1\")\n",
    "        # conv2 en 64 images de 23x23 pixels :\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation='relu', name=\"conv2\")\n",
    "        # conv3 en 128 images de 21x21 pixels :\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, 3, activation='relu', name=\"conv3\")\n",
    "        # on met à plat le résultat en 1 seul vecteur de 56 448 valeurs\n",
    "        self.flatten = tf.keras.layers.Flatten(name=\"flatten\")\n",
    "        # on passe dans le perceptron\n",
    "        self.d1 = tf.keras.layers.Dense(128, activation= 'relu',name=\"d1\")\n",
    "        self.out = tf.keras.layers.Dense(10, activation= 'softmax',name=\"output\")\n",
    "    def call(self,X_train):\n",
    "        # on appelle les attributs du constructeur :\n",
    "        conv1= self.conv1(X_train)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        flatten = self.flatten(conv3)\n",
    "        d1 = self.d1(flatten)\n",
    "        output = self.out(d1)\n",
    "        return output\n",
    "model = ConvModel()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mise en place des métriques pour suivre la performance du modele</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#définition de la fonction de cout\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# choix de la descente de gradient\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# les pertes :\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "# la précision :\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Entrainement du modèle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #prédictions sur le batch\n",
    "        predictions = model(X_train)\n",
    "        #on récupère l'erreur sur la prédiction\n",
    "        loss = loss_object(y_train, predictions)\n",
    "    # On mesure le gradient de l'erreur pour savoir comment on update le poids\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # on change les poids du modele\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    \n",
    "    # on ajoute les métriques pour les mesures\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y_train, predictions)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Validation du modele</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def valid_step(X_train, y_train):\n",
    "    predictions = model(X_train)\n",
    "    t_loss = loss_object(y_train, predictions)\n",
    "    #mise en place des métriques\n",
    "    valid_loss(t_loss)\n",
    "    valid_accuracy(y_train, predictions)\n",
    "\n",
    "images_batch = tf.image.convert_image_dtype(images_batch, dtype=tf.float32, saturate=False)\n",
    "targets_batch = tf.image.convert_image_dtype(targets_batch, dtype=tf.float32, saturate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mesure du modèle sur le dataset de validation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_batch <dtype: 'float32'>\n",
      "targets_batch <dtype: 'float32'>\n",
      " Batch 448/450, Loss:0.15564300119876862, Accuracy:48.091069793701176Epoch 1, Valid Loss: 0.0, Valid Accuracy: 46.0\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "bactch_size = 32\n",
    "b = 0\n",
    "\n",
    "print(\"images_batch\",images_batch.dtype)\n",
    "print(\"targets_batch\",targets_batch.dtype)\n",
    "\n",
    "for epoch in range(epoch):\n",
    "     # Pour le taining set :\n",
    "    for images_batch, targets_batch in train_dataset.batch(batch_size):\n",
    "        train_step(images_batch,targets_batch)\n",
    "        template = '\\r Batch {}/{}, Loss:{}, Accuracy:{}'\n",
    "        print(template.format(\n",
    "            b,len(y_train),train_loss.result(),train_accuracy.result()*100),end=\"\")\n",
    "        b += batch_size\n",
    "        \n",
    "     # Pour le validation set :\n",
    "    for images_batch, targets_batch in valid_dataset.batch(batch_size):\n",
    "        valid_step(images_batch,targets_batch)\n",
    "    \n",
    "    template = 'Epoch {}, Valid Loss: {}, Valid Accuracy: {}'\n",
    "    print(template.format(\n",
    "        epoch+1,\n",
    "        valid_loss.result(),\n",
    "        valid_accuracy.result()*100))\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
